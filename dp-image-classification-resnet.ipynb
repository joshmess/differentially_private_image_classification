{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "138caf80-c74e-4d44-8232-fbb70ca31b50",
   "metadata": {},
   "source": [
    "# Differentially Private Image Classification With ResNet\n",
    "\n",
    "Author: [Josh Messitte](https://joshmessitte.dev)\n",
    "\n",
    "Date Created: 2/12/2022\n",
    "\n",
    "Description: Training a ResNet to classify images from the CIFAR-10 dataset in an epsilon-differentially private manner using PyTorch and Opacus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69293d-4fc9-4098-ac1e-7067bdc7f014",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "This project will:\n",
    "\n",
    "\n",
    "*   Identify & tune important parameters for ϵ-DP root mean squared propogation.\n",
    "*   Use Opacus to identify layers incompatible with ϵ-DP.\n",
    "*   Train a ϵ-DP ResNet for CIFAR-10 image classification using RMSprop.\n",
    "*   Test both private and non-private models to measure accuracy, precision, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c9157f-906a-47c2-bf03-e399cdffe630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:57:46.561532Z",
     "iopub.status.busy": "2022-02-13T20:57:46.561168Z",
     "iopub.status.idle": "2022-02-13T20:57:46.567944Z",
     "shell.execute_reply": "2022-02-13T20:57:46.567304Z",
     "shell.execute_reply.started": "2022-02-13T20:57:46.561460Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3011eb0-f596-4efb-aac9-c6fa813cff5a",
   "metadata": {},
   "source": [
    "## Tuning Hyper-parameters\n",
    "\n",
    "In order to train a ϵ-DP model with Opacus, we will tune a couple of hyper-parameters to optimizemodel performance:\n",
    "\n",
    "*   Noise Multiplier: The amount of noise injected into the gradients.\n",
    "*   Max Gradient Norm: The maximum L2 norm (sum of squared values) to which per sample gradients are clipped.\n",
    "*   Delta: The targer δ for our ϵ-DP guarantee. This is the probability of any information accidentally being leaked. Because the CIFAR-10 dataset has 50k training points, our delta will be set to 1e-5 (a little less than the inverse of the size of the training set). \n",
    "\n",
    "The normal hyper-parameters for the model we will use are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ce8dba-acfc-47e0-a27a-ef022bb1e2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:57:50.938415Z",
     "iopub.status.busy": "2022-02-13T20:57:50.938119Z",
     "iopub.status.idle": "2022-02-13T20:57:50.941493Z",
     "shell.execute_reply": "2022-02-13T20:57:50.940957Z",
     "shell.execute_reply.started": "2022-02-13T20:57:50.938391Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 512\n",
    "MAX_PHYSICAL_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228c9c6-fa1c-485e-8345-3b0804661e4c",
   "metadata": {},
   "source": [
    "And the following privacy-specific hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d12c1b4-a51a-4e94-994e-64b384d80fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:57:53.442925Z",
     "iopub.status.busy": "2022-02-13T20:57:53.442502Z",
     "iopub.status.idle": "2022-02-13T20:57:53.446799Z",
     "shell.execute_reply": "2022-02-13T20:57:53.446028Z",
     "shell.execute_reply.started": "2022-02-13T20:57:53.442885Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50\n",
    "DELTA = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff08d2e-0e14-499e-9937-eed69617905b",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "Here we are loading the CIFAR-10 dataset. No data augmentation is utilized as some prior works suggest that models trained using data augmentation may underestimate the resulting risk of a privacy attack(Yu,2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "305e7a0f-c0ce-4f10-bfd9-b9712bd8aacb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:57:55.687510Z",
     "iopub.status.busy": "2022-02-13T20:57:55.687199Z",
     "iopub.status.idle": "2022-02-13T20:57:57.500949Z",
     "shell.execute_reply": "2022-02-13T20:57:57.499775Z",
     "shell.execute_reply.started": "2022-02-13T20:57:55.687485Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# These values are specific to the CIFAR-10 dataset\n",
    "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR10_STD_DEV = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR10_MEAN, CIFAR10_STD_DEV),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ce0eb9-ac1a-435e-81e6-7c73f7eb84b2",
   "metadata": {},
   "source": [
    "Then we can load the images and convert the PILImages to data of type Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6b568c-71f8-4d8a-abfd-09d71744ec67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:00.022397Z",
     "iopub.status.busy": "2022-02-13T20:58:00.022096Z",
     "iopub.status.idle": "2022-02-13T20:58:02.135687Z",
     "shell.execute_reply": "2022-02-13T20:58:02.135140Z",
     "shell.execute_reply.started": "2022-02-13T20:58:00.022374Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "DATA_ROOT = '../cifar10'\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18098296-afe2-489b-8739-555fd53f1007",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now we will create our ResNet model using the torchvision package. We will be using a ResNet18 which specifies 18 layers in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312d4672-a473-4b22-a46b-ef79e6d801dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:05.910158Z",
     "iopub.status.busy": "2022-02-13T20:58:05.909878Z",
     "iopub.status.idle": "2022-02-13T20:58:06.078013Z",
     "shell.execute_reply": "2022-02-13T20:58:06.077483Z",
     "shell.execute_reply.started": "2022-02-13T20:58:05.910134Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad81ca-d44c-4cd8-a506-7d0d2480d7f6",
   "metadata": {},
   "source": [
    "## Identifying Incompatible Layers\n",
    "\n",
    "Some layers are not compatible with Opacus due to privacy implications. For example, we discussed in class how BatchNorm layers cannot be used because ϵ-DP relies upon using only neighboring datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0eb418-6ed3-4b6c-89e5-71f6a5997a06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:08.518206Z",
     "iopub.status.busy": "2022-02-13T20:58:08.517912Z",
     "iopub.status.idle": "2022-02-13T20:58:11.218831Z",
     "shell.execute_reply": "2022-02-13T20:58:11.218168Z",
     "shell.execute_reply.started": "2022-02-13T20:58:08.518182Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opacus\n",
      "  Using cached opacus-1.0.2-py3-none-any.whl (145 kB)\n",
      "Requirement already satisfied: torch>=1.8 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from opacus) (1.9.1)\n",
      "Requirement already satisfied: scipy>=1.2 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from opacus) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from opacus) (1.21.2)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/envs/saturn/lib/python3.9/site-packages (from torch>=1.8->opacus) (3.10.0.2)\n",
      "Installing collected packages: opacus\n",
      "Successfully installed opacus-1.0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[opacus.validators.errors.ShouldReplaceModuleError(\"BatchNorm cannot support training with differential privacy. The reason for it is that BatchNorm makes each sample's normalized value depend on its peers in a batch, ie the same sample x will get normalized to a different value depending on who else is on its batch. Privacy-wise, this means that we would have to put a privacy mechanism there too. While it can in principle be done, there are now multiple normalization layers that do not have this issue: LayerNorm, InstanceNorm and their generalization GroupNorm are all privacy-safe since they don't have this property.We offer utilities to automatically replace BatchNorms to GroupNorms and we will release pretrained models to help transition, such as GN-ResNet ie a ResNet using GroupNorm, pretrained on ImageNet\"),\n",
       " opacus.validators.errors.ShouldReplaceModuleError(\"BatchNorm cannot support training with differential privacy. The reason for it is that BatchNorm makes each sample's normalized value depend on its peers in a batch, ie the same sample x will get normalized to a different value depending on who else is on its batch. Privacy-wise, this means that we would have to put a privacy mechanism there too. While it can in principle be done, there are now multiple normalization layers that do not have this issue: LayerNorm, InstanceNorm and their generalization GroupNorm are all privacy-safe since they don't have this property.We offer utilities to automatically replace BatchNorms to GroupNorms and we will release pretrained models to help transition, such as GN-ResNet ie a ResNet using GroupNorm, pretrained on ImageNet\"),\n",
       " opacus.validators.errors.ShouldReplaceModuleError(\"BatchNorm cannot support training with differential privacy. The reason for it is that BatchNorm makes each sample's normalized value depend on its peers in a batch, ie the same sample x will get normalized to a different value depending on who else is on its batch. Privacy-wise, this means that we would have to put a privacy mechanism there too. While it can in principle be done, there are now multiple normalization layers that do not have this issue: LayerNorm, InstanceNorm and their generalization GroupNorm are all privacy-safe since they don't have this property.We offer utilities to automatically replace BatchNorms to GroupNorms and we will release pretrained models to help transition, such as GN-ResNet ie a ResNet using GroupNorm, pretrained on ImageNet\"),\n",
       " opacus.validators.errors.ShouldReplaceModuleError(\"BatchNorm cannot support training with differential privacy. The reason for it is that BatchNorm makes each sample's normalized value depend on its peers in a batch, ie the same sample x will get normalized to a different value depending on who else is on its batch. Privacy-wise, this means that we would have to put a privacy mechanism there too. While it can in principle be done, there are now multiple normalization layers that do not have this issue: LayerNorm, InstanceNorm and their generalization GroupNorm are all privacy-safe since they don't have this property.We offer utilities to automatically replace BatchNorms to GroupNorms and we will release pretrained models to help transition, such as GN-ResNet ie a ResNet using GroupNorm, pretrained on ImageNet\"),\n",
       " opacus.validators.errors.ShouldReplaceModuleError(\"BatchNorm cannot support training with differential privacy. The reason for it is that BatchNorm makes each sample's normalized value depend on its peers in a batch, ie the same sample x will get normalized to a different value depending on who else is on its batch. Privacy-wise, this means that we would have to put a privacy mechanism there too. While it can in principle be done, there are now multiple normalization layers that do not have this issue: LayerNorm, InstanceNorm and their generalization GroupNorm are all privacy-safe since they don't have this property.We offer utilities to automatically replace BatchNorms to GroupNorms and we will release pretrained models to help transition, such as GN-ResNet ie a ResNet using GroupNorm, pretrained on ImageNet\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if opacus is not installed, it can be installed by specifying a command line statement: \n",
    "!pip3 install opacus\n",
    "\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "errors = ModuleValidator.validate(model, strict=False)\n",
    "errors[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9ccd0-da7f-46ce-9117-9451a4b0772a",
   "metadata": {},
   "source": [
    "We can remove incompatible layers using ModuleValidator.fix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b024fd6-c97c-4533-9de0-a1173394dcce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:17.795916Z",
     "iopub.status.busy": "2022-02-13T20:58:17.795601Z",
     "iopub.status.idle": "2022-02-13T20:58:17.882971Z",
     "shell.execute_reply": "2022-02-13T20:58:17.882417Z",
     "shell.execute_reply.started": "2022-02-13T20:58:17.795887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModuleValidator.fix(model)\n",
    "ModuleValidator.validate(model,strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c24fd-e818-4b47-be40-1e3563c904f6",
   "metadata": {},
   "source": [
    "## Utilizing GPUs\n",
    "\n",
    "SaturnCloud supports GPUs, so we can specify our device to be CUDA-compatible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d85db122-1b2c-4a82-9605-18f12970c41d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:20.874437Z",
     "iopub.status.busy": "2022-02-13T20:58:20.874133Z",
     "iopub.status.idle": "2022-02-13T20:58:23.918118Z",
     "shell.execute_reply": "2022-02-13T20:58:23.917384Z",
     "shell.execute_reply.started": "2022-02-13T20:58:20.874413Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36755080-ce56-4acb-9d2a-5417f7267095",
   "metadata": {},
   "source": [
    "## Optimization Method & Loss Criterion\n",
    "\n",
    "We can specify our loss criterion (Cross Entropy Loss) and our optimization method (RMSprop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e368e841-18d1-4557-b43c-a942f47f735d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:27.067499Z",
     "iopub.status.busy": "2022-02-13T20:58:27.067168Z",
     "iopub.status.idle": "2022-02-13T20:58:27.071467Z",
     "shell.execute_reply": "2022-02-13T20:58:27.070811Z",
     "shell.execute_reply.started": "2022-02-13T20:58:27.067475Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d07499-d7dc-43e3-a4d1-5352a2b57836",
   "metadata": {},
   "source": [
    "## Privacy Engine\n",
    "\n",
    "We now take our privacy-specific hyper-parameters and attach them to the privacy engine provided by Opacus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1fde2d0-d2db-4bd7-961a-16e90fbfddee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:31.410048Z",
     "iopub.status.busy": "2022-02-13T20:58:31.409749Z",
     "iopub.status.idle": "2022-02-13T20:58:32.160992Z",
     "shell.execute_reply": "2022-02-13T20:58:32.160335Z",
     "shell.execute_reply.started": "2022-02-13T20:58:31.410026Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sigma=0.39066894531249996 and C=1.2\n"
     ]
    }
   ],
   "source": [
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    epochs=EPOCHS,\n",
    "    target_epsilon=EPSILON,\n",
    "    target_delta=DELTA,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    ")\n",
    "\n",
    "print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c1f42b-b6db-4ae8-beb4-197e59b15938",
   "metadata": {},
   "source": [
    "## Accuracy Calculator\n",
    "\n",
    "This method will measure the accuracy of our model (training $ testing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc3b6ce7-b8c5-4d6c-88d2-b538955dfe5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:37.310367Z",
     "iopub.status.busy": "2022-02-13T20:58:37.309948Z",
     "iopub.status.idle": "2022-02-13T20:58:37.314511Z",
     "shell.execute_reply": "2022-02-13T20:58:37.313955Z",
     "shell.execute_reply.started": "2022-02-13T20:58:37.310326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca381c4c-85aa-4c96-af9f-00b9f4ed5a84",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "\n",
    "This function trains the model for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33abdb8d-f735-47d4-8f94-247f8e943524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:39.797348Z",
     "iopub.status.busy": "2022-02-13T20:58:39.797056Z",
     "iopub.status.idle": "2022-02-13T20:58:39.805449Z",
     "shell.execute_reply": "2022-02-13T20:58:39.804759Z",
     "shell.execute_reply.started": "2022-02-13T20:58:39.797325Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.lib.function_base import append\n",
    "import numpy as np\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "    passed = []\n",
    "    \n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 200 == 0 and epoch not in passed:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "                passed.append(epoch)\n",
    "                print(\n",
    "                    f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                    f\"Loss: {np.mean(losses):.6f} \"\n",
    "                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3fb56-ee4b-48ad-bf2f-a81870046b33",
   "metadata": {},
   "source": [
    "## Test Function\n",
    "\n",
    "Our test function will validate our model on the 10k large test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25998cf7-7621-4668-9341-87ac0ec32a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:58:47.348584Z",
     "iopub.status.busy": "2022-02-13T20:58:47.348271Z",
     "iopub.status.idle": "2022-02-13T20:58:47.353824Z",
     "shell.execute_reply": "2022-02-13T20:58:47.353292Z",
     "shell.execute_reply.started": "2022-02-13T20:58:47.348560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "    top1_avg = np.mean(top1_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\tTest set:\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"Acc: {top1_avg * 100:.6f} \"\n",
    "    )\n",
    "    return np.mean(top1_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c26e1-285c-46f3-847c-304c3ae81212",
   "metadata": {},
   "source": [
    "## Train the ResNet\n",
    "\n",
    "This method trains the ResNet model on the 50k training images using our RMSprop optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61a91bce-9388-4774-80d3-3b50459b6a25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T20:59:00.626807Z",
     "iopub.status.busy": "2022-02-13T20:59:00.626503Z",
     "iopub.status.idle": "2022-02-13T21:22:00.320751Z",
     "shell.execute_reply": "2022-02-13T21:22:00.320127Z",
     "shell.execute_reply.started": "2022-02-13T20:59:00.626783Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90609b1584546e6a21b70083a30b063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Epoch: 1 \tLoss: 2.821287 Acc@1: 14.948530 (ε = 13.22, δ = 1e-05)\n",
      "\tTrain Epoch: 2 \tLoss: 1.736835 Acc@1: 39.619147 (ε = 17.48, δ = 1e-05)\n",
      "\tTrain Epoch: 3 \tLoss: 1.707476 Acc@1: 46.622677 (ε = 20.48, δ = 1e-05)\n",
      "\tTrain Epoch: 4 \tLoss: 1.721353 Acc@1: 49.714974 (ε = 22.82, δ = 1e-05)\n",
      "\tTrain Epoch: 5 \tLoss: 1.727507 Acc@1: 51.502854 (ε = 25.11, δ = 1e-05)\n",
      "\tTrain Epoch: 6 \tLoss: 1.724925 Acc@1: 53.482387 (ε = 26.89, δ = 1e-05)\n",
      "\tTrain Epoch: 7 \tLoss: 1.687457 Acc@1: 55.355920 (ε = 28.64, δ = 1e-05)\n",
      "\tTrain Epoch: 8 \tLoss: 1.694153 Acc@1: 56.062868 (ε = 30.38, δ = 1e-05)\n",
      "\tTrain Epoch: 9 \tLoss: 1.669977 Acc@1: 57.236402 (ε = 32.13, δ = 1e-05)\n",
      "\tTrain Epoch: 10 \tLoss: 1.644540 Acc@1: 58.232808 (ε = 33.74, δ = 1e-05)\n",
      "\tTrain Epoch: 11 \tLoss: 1.643082 Acc@1: 58.683280 (ε = 35.10, δ = 1e-05)\n",
      "\tTrain Epoch: 12 \tLoss: 1.643017 Acc@1: 59.585600 (ε = 36.43, δ = 1e-05)\n",
      "\tTrain Epoch: 13 \tLoss: 1.634004 Acc@1: 59.782648 (ε = 37.78, δ = 1e-05)\n",
      "\tTrain Epoch: 14 \tLoss: 1.626882 Acc@1: 60.622883 (ε = 39.10, δ = 1e-05)\n",
      "\tTrain Epoch: 15 \tLoss: 1.620721 Acc@1: 61.077686 (ε = 40.47, δ = 1e-05)\n",
      "\tTrain Epoch: 16 \tLoss: 1.620392 Acc@1: 61.402383 (ε = 41.76, δ = 1e-05)\n",
      "\tTrain Epoch: 17 \tLoss: 1.595255 Acc@1: 62.160306 (ε = 43.11, δ = 1e-05)\n",
      "\tTrain Epoch: 18 \tLoss: 1.582547 Acc@1: 62.343033 (ε = 44.47, δ = 1e-05)\n",
      "\tTrain Epoch: 19 \tLoss: 1.554578 Acc@1: 63.389779 (ε = 45.80, δ = 1e-05)\n",
      "\tTrain Epoch: 20 \tLoss: 1.564409 Acc@1: 63.203904 (ε = 47.13, δ = 1e-05)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    train(model, train_loader, optimizer, epoch + 1, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c704ec5-9a7e-4021-85a8-ca107b32c1d8",
   "metadata": {},
   "source": [
    "## Test the ResNet on Test Data\n",
    "Now we test the trained model on the 10k testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b1d41a1-4ba9-48a7-9de4-da28647c30d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T21:23:55.301402Z",
     "iopub.status.busy": "2022-02-13T21:23:55.301095Z",
     "iopub.status.idle": "2022-02-13T21:23:57.049511Z",
     "shell.execute_reply": "2022-02-13T21:23:57.048869Z",
     "shell.execute_reply.started": "2022-02-13T21:23:55.301377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest set:Loss: 1.743414 Acc: 60.087316 \n"
     ]
    }
   ],
   "source": [
    "top1_acc = test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495265d-35fa-47bd-bdce-887e890e95f1",
   "metadata": {},
   "source": [
    "## References\n",
    "*   Yu, D., Zhang, H., Chen, W., Yin, J., & Liu, T.-Y. (2021). How Does Data Augmentation Affect Privacy in Machine Learning? arXiv [cs.LG]. Opgehaal van http://arxiv.org/abs/2007.10567\n",
    "*   He, K., Zhang, X., Ren, S., & Sun, J. (2015). Deep Residual Learning for Image Recognition. arXiv [cs.CV]. Opgehaal van http://arxiv.org/abs/1512.03385\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
